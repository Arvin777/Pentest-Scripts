#!/usr/bin/python3
#parse.py

import urllib3
from urllib.request import urlopen
from bs4 import BeautifulSoup

http = urllib3.PoolManager()

url = urlopen('http://www.megacorpone.com')

page = url.read()
soup = BeautifulSoup(page, features="html.parser")

print (soup.text)

#response = http.request('GET', url)
#print(response.data.decode('utf-8'))


from bs4 import BeautifulSoup

http = urllib3.PoolManager()

url = urlopen('http://192.168.51.68:8080/crawling')

page = url.read()
soup = BeautifulSoup(page, features="html.parser")

abc = []
for link in soup.find_all('a'):
	abc = link.get('href')
	print (abc)
	
for i in abc:
	newurl = (f"http://192.168.51.68:8080/{i}")
	print (f"http://192.168.56.68:8080/{i}")
	response = requests.get(newurl)
	print (response.text)